p8105_hw2_sef2183
================
Sarah Forrest
2022-09-27

# Problem 0

``` r
library(tidyverse)
library(readxl)
```

# Problem 1

## Read and Clean the Data

``` r
# My method
subway_df = 
  read_csv("data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>%
  janitor::clean_names() %>%
  select(line, station_name, station_latitude, station_longitude, route1, route2, route3, route4, route5, route6, route7, route8, route9, route10, route11, entry, vending, entrance_type, ada) %>%
  mutate(entry = recode(entry, "YES" = TRUE,  "NO" = FALSE))

# Jeff's method
trans_ent = 
  read_csv(
    "data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
    col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) %>% 
  janitor::clean_names() %>% 
  select(
    line, station_name, station_latitude, station_longitude, 
    starts_with("route"), entry, exit_only, vending, entrance_type, 
    ada) %>% 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

## Dataset Description:

This dataset contains the variables: `line`, `station_name`,
`station_latitude`, `station_longitude`, routes served (route1-route11),
`entry`, `vending`, `entrance_type`, and `ada` (ADA compliance).

So far, I imported the CSV file with the data using the `read_csv`
function and a relative path to the data file. Then, I used the pipe
operator to feed the data frame into the `janitor` package’s
`clean_names` function to convert all variable names to lower case and
put underscores in the gaps Then, I used the pipe operator again to feed
the output of the `clean_names` function to the `select` function to
retain only the variables of interest in the data frame. Then, I used
the pipe operator again to feed the output of the `select` function into
the `recode` function within `mutate` to convert the entry variable from
character (`YES` vs `NO`) to a logical variable. Finally, the outcome of
all of these processes are stored in the tibble `subway_df`. I printed
out the data set to check the variables that were included in it and
also checked that the entry variable was logical using the `is.logical`
function which returned “TRUE”.

The dimensions of the resulting `subway_df` tibble is 1,868 rows
(observations) by 19 columns (variables).

These data are not tidy. Variables `route1`-`route11` span 11 columns in
the dataset. In order to be tidy, there should just be 1 column for the
variable `route_number` with values for each route number and another
column, `route_name` for the name of the corresponding subway.

## Dataset Questions:

This produces a dataframe in which the the number of rows in this
dataset is the number of unique stations:

``` r
# My method
distinct_stations_df = distinct(subway_df, station_name, line, .keep_all = TRUE)
nrow(distinct_stations_df)
## [1] 465

# Jeff's method
trans_ent %>% 
  select(station_name, line) %>% 
  distinct
## # A tibble: 465 × 2
##    station_name             line    
##    <chr>                    <chr>   
##  1 25th St                  4 Avenue
##  2 36th St                  4 Avenue
##  3 45th St                  4 Avenue
##  4 53rd St                  4 Avenue
##  5 59th St                  4 Avenue
##  6 77th St                  4 Avenue
##  7 86th St                  4 Avenue
##  8 95th St                  4 Avenue
##  9 9th St                   4 Avenue
## 10 Atlantic Av-Barclays Ctr 4 Avenue
## # … with 455 more rows
```

Answer: there are 465 distinct stations.

This produces a dataframe in which the number of rows is the number of
ADA compliant stations:

``` r
# My method
sum(distinct_stations_df$ada == "TRUE")
## [1] 84

# Jeff's method
trans_ent %>% 
  filter(ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
## # A tibble: 84 × 2
##    station_name                   line           
##    <chr>                          <chr>          
##  1 Atlantic Av-Barclays Ctr       4 Avenue       
##  2 DeKalb Av                      4 Avenue       
##  3 Pacific St                     4 Avenue       
##  4 Grand Central                  42nd St Shuttle
##  5 34th St                        6 Avenue       
##  6 47-50th Sts Rockefeller Center 6 Avenue       
##  7 Church Av                      6 Avenue       
##  8 21st St                        63rd Street    
##  9 Lexington Av                   63rd Street    
## 10 Roosevelt Island               63rd Street    
## # … with 74 more rows
```

Answer: 84 distinct stations are ADA compliant.

To compute the proportion of station entrances / exits without vending
allow entrance, station entrances that do not allow vending are excluded
and then the mean of the entry variable is taken (which is logical), to
produce the desired proportion:

``` r
trans_ent %>% 
  filter(vending == "NO") %>% 
  pull(entry) %>% 
  mean
## [1] 0.3770492
```

Answer: 0.3770492 station entrances / exits without vending allow
entrance.

This produces a dataframe in which the number of rows is the number of
distinct stations that serve the A train:

``` r
# My method
subway_df$route8 <- as.character(subway_df$route8)
subway_df$route9 <- as.character(subway_df$route9)
subway_df$route10 <- as.character(subway_df$route10)
subway_df$route11 <- as.character(subway_df$route11)

subway_long_df =
  subway_df %>%
  pivot_longer(
    route1:route11,
    names_to = "route_number",
    names_prefix = "route",
    values_to = "route_name")

distinct_stations_long_df = distinct(subway_long_df, station_name, line, .keep_all = TRUE)

sum(distinct_stations_long_df$route_name == "A")
## [1] 60

# Jeff's method: 
trans_ent %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A") %>% 
  select(station_name, line) %>% 
  distinct
## # A tibble: 60 × 2
##    station_name                  line           
##    <chr>                         <chr>          
##  1 Times Square                  42nd St Shuttle
##  2 125th St                      8 Avenue       
##  3 145th St                      8 Avenue       
##  4 14th St                       8 Avenue       
##  5 168th St - Washington Heights 8 Avenue       
##  6 175th St                      8 Avenue       
##  7 181st St                      8 Avenue       
##  8 190th St                      8 Avenue       
##  9 34th St                       8 Avenue       
## 10 42nd St                       8 Avenue       
## # … with 50 more rows
```

Answer: 60 distinct stations serve the A train.

This produces a dataframe in which the number of rows is the number of
distinct stations that serve the A train and are ADA compliant:

``` r
# My method
a_df = filter(distinct_stations_long_df, route_name == "A") 
sum(a_df$ada == "TRUE")
## [1] 17

# Jeff's method
trans_ent %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A", ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
## # A tibble: 17 × 2
##    station_name                  line            
##    <chr>                         <chr>           
##  1 14th St                       8 Avenue        
##  2 168th St - Washington Heights 8 Avenue        
##  3 175th St                      8 Avenue        
##  4 34th St                       8 Avenue        
##  5 42nd St                       8 Avenue        
##  6 59th St                       8 Avenue        
##  7 Inwood - 207th St             8 Avenue        
##  8 West 4th St                   8 Avenue        
##  9 World Trade Center            8 Avenue        
## 10 Times Square-42nd St          Broadway        
## 11 59th St-Columbus Circle       Broadway-7th Ave
## 12 Times Square                  Broadway-7th Ave
## 13 8th Av                        Canarsie        
## 14 Franklin Av                   Franklin        
## 15 Euclid Av                     Fulton          
## 16 Franklin Av                   Fulton          
## 17 Howard Beach                  Rockaway
```

Answer: 17 of the stations that serve the A train are ADA compliant.

# Problem 2

Below, the Mr. Trash Wheel data from `Trash Wheel Collection Data.xlsx`
is imported and cleaned. The process begins with data import from cells
A2 to N549 (omitting the figure at the top of the sheet and the summary
row at the bottom). Then, variable names are cleaned using
`clean_names()`.A `dataset` variable was added to keep track of which
Trash Wheel is which when the datasets are merged in future steps. As
part of the data import, `sports_balls` is also rounded to the nearest
integer and converted to an integer variable using `as.integer()`.
Finally, `year` is converted to a numeric variable so that it is the
same type as `year` in the Professor Trash Wheel dataset and the two can
be successfully merged in future steps:

``` r
mrtrashwheel_df =
  read_excel("data/Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel", range = "A2:N549") %>%
  janitor::clean_names() %>%
  mutate(dataset = "mr") %>%
  mutate(sports_balls = as.integer(sports_balls)) %>%
  mutate(year = as.numeric(year))
```

The following code is written to ensure that `sports_balls` was
successfully converted to an integer variable using `as.integer()`:

``` r
class(mrtrashwheel_df$sports_balls)
## [1] "integer"
```

Below, the Professor Trash Wheel data from
`Trash Wheel Collection Data.xlsx` is imported and cleaned. The process
begins with data import from cells A2 to M96 (omitting the figure at the
top of the sheet and the summary row at the bottom). Then, variable
names are cleaned using `clean_names()`. A `dataset` variable was added
to keep track of which Trash Wheel is which when the datasets are merged
in future steps:

``` r
professortrashwheel_df =
  read_excel("data/Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel", range = "A2:M96") %>%
  janitor::clean_names() %>%
  mutate(dataset = "prof")
```

``` r
trashwheel_df = full_join(mrtrashwheel_df, professortrashwheel_df)

trashwheel_df
## # A tibble: 641 × 15
##    dumpster month  year date                weight_tons volume…¹ plast…² polys…³
##       <dbl> <chr> <dbl> <dttm>                    <dbl>    <dbl>   <dbl>   <dbl>
##  1        1 May    2014 2014-05-16 00:00:00        4.31       18    1450    1820
##  2        2 May    2014 2014-05-16 00:00:00        2.74       13    1120    1030
##  3        3 May    2014 2014-05-16 00:00:00        3.45       15    2450    3100
##  4        4 May    2014 2014-05-17 00:00:00        3.1        15    2380    2730
##  5        5 May    2014 2014-05-17 00:00:00        4.06       18     980     870
##  6        6 May    2014 2014-05-20 00:00:00        2.71       13    1430    2140
##  7        7 May    2014 2014-05-21 00:00:00        1.91        8     910    1090
##  8        8 May    2014 2014-05-28 00:00:00        3.7        16    3580    4310
##  9        9 June   2014 2014-06-05 00:00:00        2.52       14    2400    2790
## 10       10 June   2014 2014-06-11 00:00:00        3.76       18    1340    1730
## # … with 631 more rows, 7 more variables: cigarette_butts <dbl>,
## #   glass_bottles <dbl>, grocery_bags <dbl>, chip_bags <dbl>,
## #   sports_balls <int>, homes_powered <dbl>, dataset <chr>, and abbreviated
## #   variable names ¹​volume_cubic_yards, ²​plastic_bottles, ³​polystyrene
```

## Dataset Description:

-   The number of observations in the resulting dataset is 641.

-   Examples of key variables in the dataset include: `dumpster`,
    `month`, `year`, `date`, `weight_tons`, `volume_cubic_yards`,
    `plastic_bottles`, `polystyrene`, `cigarette_butts`,
    `glass_bottles`, `grocery_bags`, `chip_bags`, `sports_balls`,
    `homes_powered`, and `dataset`, which indicates which Trash Wheel
    (Mr. or Professor) the data is from.

-   Using inline R to take the sum of `weight_tons` from
    `professortrashwheel_df`, the total weight of trash collected by
    Professor Trash Wheel is 190.12 tons. This can be double checked
    another way by running the following code, which filters only the
    trash collected by Professor Trash Wheel from the combined dataset,
    and then calculates the sum of `weight_tons`:

``` r
trashwheel_df %>% 
  filter(dataset == "prof") %>%
  pull(weight_tons) %>% 
  sum
## [1] 190.12
```

Answer: the total weight of trash collected by Professor Trash Wheel is
190.12 tons.

-   To calculate the total number of sports balls collected by Mr. Trash
    Wheel in 2020, the following code filters only the trash collected
    by Mr. Trash Wheel from the combined dataset in 2020, and then
    calculates the sum of `sports_balls`:

``` r
trashwheel_df %>% 
  filter(dataset == "mr") %>%
  filter(year == "2020") %>%
  pull(sports_balls) %>% 
  sum
## [1] 856
```

Answer: the total number of sports balls collected by Mr. Trash Wheel in
2020 was 856.

Inline R can also be used to report the answer to this question by
running the following code:

``` r
mrtrashwheel_2020_df =
  filter(mrtrashwheel_df, year == 2020)
```

Answer: the total number of sports balls collected by Mr. Trash Wheel in
2020 was 856.

# Problem 3

Below, the data from `fivethirtyeight_datasets/pols-month.csv` is
imported and cleaned. The process begins with cleaning variable names
using `clean_names()` and separating the `mon` variable into 3 new
variables: `year`, `month`, and `day`. Then, the month numbers are
replaced with month names and a `president` variable is created, which
takes values `prez_gop` and `prez_dem`. After that, `prez_dem`,
`prez_gop`, and `day` are removed from the dataset and `year` is
converted to an numeric variable using `as.numeric()`:

``` r
pols_month_df = 
  read_csv("data/fivethirtyeight_datasets/pols-month.csv") %>%
  janitor::clean_names() %>%
  separate(mon, into = c("year", "month", "day"), sep = '-') %>%
  mutate(
    month = recode(month, "01" = 'January', "02" = 'February', "03" = 'March', "04" = 'April', "05" = 'May', "06" = 'June', "07" = 'July', "08" = 'August', "09" = 'September', "10" = 'October', "11" = 'November', "12" = 'December')) %>%
  mutate(
    president = case_when(prez_gop == 1 ~ "gop",
                          prez_gop != 1 ~ "dem")) %>%
  select(-prez_gop, -prez_dem, -day) %>%
  mutate(year = as.numeric(year))
```

Below, the data from `fivethirtyeight_datasets/snp.csv` is imported and
cleaned. The process begins with cleaning variable names using
`clean_names()` and separating the `date` variable into 3 new
variables:`month`,`day` and `year`. Then, the month numbers are replaced
with month names and “20” is added to the front of the values of `year`,
turning “11” into “2011”, for example. After that, the dataset is
arranged according to year and month, and organized so that year and
month are the leading columns. `day` is dropped for consistency across
datasets and `year` is converted to an numeric variable using
`as.numeric()`:

``` r
snp_df = 
  read_csv("data/fivethirtyeight_datasets/snp.csv") %>%
  janitor::clean_names() %>%
  separate(date, into = c("month", "day", "year"), sep = '/') %>%
  mutate(
    month = recode(month, "1" = 'January', "2" = 'February', "3" = 'March', "4" = 'April', "5" = 'May', "6" = 'June', "7" = 'July', "8" = 'August', "9" = 'September', "10" = 'October', "11" = 'November', "12" = 'December')) %>%
  mutate(year = paste0("20", year)) %>%
  arrange(year, month) %>%
  relocate(year, month) %>%
  select(-day) %>%
  mutate(year = as.numeric(year))
```

Below, the data from `fivethirtyeight_datasets/unemployment.csv` is
imported and cleaned. The process begins with cleaning variable names
using `clean_names()` and switching the dataset from “wide” to “long”
format using `pivot_longer()`. All of the specific month column names
(jan - dec) are combined into a single `month` variable and the values
that the previous columns held are stored in a new `unemployment`
variable. Then, the month name abbreviations are replaced with the full
month names, turning “jan” into “January” for example, for consistency
accross datasets:

``` r
unemployment_df = 
  read_csv("data/fivethirtyeight_datasets/unemployment.csv") %>%
  janitor::clean_names() %>%
  pivot_longer(jan:dec,
    names_to = "month", 
    values_to = "unemployment") %>%
  mutate(
    month = recode(month, "jan" = 'January', "feb" = 'February', "mar" = 'March', "apr" = 'April', "may" = 'May', "jun" = 'June', "jul" = 'July', "aug" = 'August', "sep" = 'September', "oct" = 'October', "nov" = 'November', "dec" = 'December'))
```

Below, the three datasets are merged into a single dataframe.
`merged_df`. `snp_df` is merged into `pols_month_df`, and
`unemployment_df` is merged into the result using `left_join()`:

``` r
merged_df = 
  left_join(pols_month_df, snp_df) %>%
  left_join(., unemployment_df)

merged_df
## # A tibble: 822 × 11
##     year month     gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem presi…¹ close
##    <dbl> <chr>       <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>   <dbl>
##  1  1947 January        23      51     253      23      45     198 dem        NA
##  2  1947 February       23      51     253      23      45     198 dem        NA
##  3  1947 March          23      51     253      23      45     198 dem        NA
##  4  1947 April          23      51     253      23      45     198 dem        NA
##  5  1947 May            23      51     253      23      45     198 dem        NA
##  6  1947 June           23      51     253      23      45     198 dem        NA
##  7  1947 July           23      51     253      23      45     198 dem        NA
##  8  1947 August         23      51     253      23      45     198 dem        NA
##  9  1947 September      23      51     253      23      45     198 dem        NA
## 10  1947 October        23      51     253      23      45     198 dem        NA
## # … with 812 more rows, 1 more variable: unemployment <dbl>, and abbreviated
## #   variable name ¹​president
```

## Dataset Descriptions:

The pols month dataset contains the variables: `year`, `month`,
`gov_gop`, `sen_gop`, `rep_gop`, `gov_dem`, `sen_dem`, `rep_dem`, and
`president`. The snp dataset contains the variables: `year`, `month`,
and `close`. The unemployment dataset contains the variables: `year`,
`month`, and `unemployment`.

Using inline R, the resulting merged dataset contains 822
rows/observations and 11 columns/variables. The range of years in the
dataset is: 1947, 2015. It contains the variables: `year`, `month`,
`gov_gop`, `sen_gop`, `rep_gop`, `gov_dem`, `sen_dem`, `rep_dem`,
`president`, `close`, and `unemployment`.
